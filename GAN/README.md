# GAN

## Table of Contents
- [Generative Adversarial Networks](#generative-adversarial-networks)
  - [2017.4](#2017-4)
  - [2017.8](#2017-8)

## Generative Adversarial Networks

### 2017 4
**Machine Learning**
机器学习的模型可大体分为两类，生成模型（Generative Model）和判别模型（Discriminative Model）。
1. 判别模型需要输入变量x ，通过某种模型来预测p(y|x) 。
2. 生成模型是给定某种隐含信息，来随机产生观测数据。

什么是机器学习？
一句话来概括就是，在训练过程中给予回馈，使得结果接近我们的期望。
1. 对于分类问题（classification），我们希望loss在接近bound以后，就不要再有变化，所以我们选择交叉熵（Cross Entropy）作为回馈；
2. 在回归问题（regression）中，我们则希望loss只有在两者一摸一样时才保持不变，所以选择点之间的欧式距离（MSE）作为回馈。

**损失函数**（回馈）的选择，会明显影响到训练结果的质量，是设计模型的重中之重。这五年来，神经网络的变种已有不下几百种，但损失函数却寥寥无几。
例如caffe的官方文档中，只提供了八种标准损失函数 Caffe | Layer Catalogue [CaffeLayerCatalogue](http://caffe.berkeleyvision.org/tutorial/layers.html)。

- 对于**判别模型**，损失函数是容易定义的，因为输出的目标相对简单。
- 但对于**生成模型**，损失函数的定义就不是那么容易。
例如:
  - 对于NLP方面的生成语句，虽然有BLEU这一优秀的衡量指标，但由于难以求导，以至于无法放进模型训练；
  - 对于生成猫咪图片的任务，如果简单地将损失函数定义为“和已有图片的欧式距离”，那么结果将是数据库里图片的诡异混合，效果惨不忍睹。

> 当我们希望神经网络画一只猫的时候，显然是希望这张图有一个动物的轮廓、带质感的毛发、和一个霸气的眼神，而不是冷冰冰的欧式距离最优解。如何将我们对于猫的期望放到模型中训练呢？这就是GAN的Adversarial部分解决的问题。

**Adversarial：对抗（互怼 ）**

在generative部分提到了，我们对于猫（生成结果）的期望，往往是一个暧昧不清，难以数学公理化定义的范式。但等一下，说到处理暧昧不清、难以公理化的问题，之前提到的判别任务不也是吗？比如图像分类，一堆RGB像素点和最后N类别的概率分布模型，显然是无法从传统数学角度定义的。那为何，不把**生成模型的回馈部分**，交给判别模型呢？这就是Goodfellow天才般的创意--他将机器学习中的两大类模型，**Generative和Discrimitive**给紧密地联合在了一起。

模型一览：

![Gan](./image/1.png)

对抗生成网络主要由生成部分G，和判别部分D组成。
训练过程描述如下：

1. 输入噪声（隐藏变量）z
2. 通过生成部分G 得到x_{fake}=G(z)
3. 从真实数据集中取一部分真实数据x_{real}
4. 将两者混合x=x_{fake} + x_{real}
5. 将数据喂入判别部分D ，给定标签x_{fake}=0,x_{real}=1 （简单的二类分类器）
6. 按照分类结果，回传loss

在整个过程中，D要尽可能的使D(G(z))=0，D(x_{real})=1（火眼晶晶，不错杀也不漏杀）。而G则要使得D(G(z))=1，**即让生成的图片尽可能以假乱真**。整个训练过程就像是两个玩家在相互对抗，也正是这个名字Adversarial的来源。在论文中[1406.2661] [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661)，Goodfellow从理论上证明了该算法的收敛性，以及在模型收敛时，生成数据具有和真实数据相同的分布（保证了模型效果）。

从研究角度，GAN给众多生成模型提供了一种新的训练思路，催生了许多后续作品。

例如根据自己喜好定制二次元妹子（逃），根据文字生成对应描述图片（[Newmu/dcgan_code](https://github.com/Newmu/dcgan_code), [hanzhanggit/StackGAN](https://github.com/hanzhanggit/StackGAN))，

甚至利用标签生成3D宜家家居模型（[zck119/3dgan-release](https://github.com/zck119/3dgan-release)），

这些作品的效果无一不令人惊叹。同时，难人可贵的是这篇论文有很强的数学论证，不同于前几年的套模型的结果说话，而是从理论上保证了模型的可靠性。虽然目前训练还时常碰到困难，后续已有更新工作改善该问题（WGAN, Loss Sensetive GAN, Least Square GAN)，相信终有一日能克服。

### 2017 8
**GAN对人工智能研究的意义和未来的发展方向**

GAN对于生成式模型的发展具有重要的意义，其作为一种生成式方法能够有效解决建立自然性解释数据的生成难题，尤其是对于生成高维数据，GAN所采用的神经网络结构不限制生成维度，极大的扩展了生成数据样本的范围。

GAN所采用的神经网络结构能够整合各类损失函数，增加了AI设计的自由度。GAN的训练过程创新性地将两个神经网络的对抗作为训练准则，并允许使用反向传播机制来进行训练，在训练过程中没有复杂的变分下界也不需要使用马尔可夫链方法（效率较低）以及做各种近似推理，大大改善了生成式模型的训练难度和训练效率。

GAN的生成过程不需要繁琐的采样序列，可以直接进行新样本的采样和推断，提高了新样本的生成效率。对抗训练方法摒弃了直接对真实数据的复制或平均，增加了生成样本的多样性。GAN在实践中生成的样本更易于人类理解，比如GAN能够生成十分清晰的图像。

GAN除了对生成式模型的贡献外，对于半监督学习的研究和发展也有启发。因为在GAN学习的过程中不需要制定数据标，尽管其提出的目的不是半监督学习，但是GAN的训练过程可以用来实施半监督学习中无标签数据对模型的预训练过程。具体来说就是先利用无标签数据训练GAN，再基于训练好的GAN对数据的理解，利用小部分有标签数据训练判别器，可以很好的进行传统分类与回归任务。

缺点：
* GAN采用的是对抗学习准则，我们目前从理论上还不能判断模型的收敛性和均衡点的存在性。
* GAN在训练过程中需要保证两个对抗网络的平衡与同步，否则难以得到很好的训练效果。而实际训练过程中，两个对抗网络的同步把控并不容易，导致了训练过程变得不稳定。

**发展、应用**
如何根据简单随机的输入生成多样的、能够与人类交互的数据，是近期GAN的一个应用的方向；
从GAN与其他机器学习方法交叉训练的角度来说，如何将GAN与特征学习、模仿学习和强化学习等技术更好地融合，开发出新的AI应用或促进这些学习方法的发展，是一个很有意义的发展方向；
从长远的角度来说，如何利用GAN推动人工智能的发展与应用、提升人工智能理解世界的能力、或者是激发人工智能的创造力是非常值得业界思考的方向。

作为一个具有“无限”生成能力的模型，GAN的最直接应用就是建模（生成与数据分布一致的数据样本），比如：生成图像和视频。
还有就是利用GAN进行模拟人工系统的生成和计算实验的分析，对平行控制中的人工系统和实际系统平行执行的过程通过建模的方式进行分析和评估，最后以平行方式来执行对复杂系统的控制的实现。在这一方面可以进行人工系统的预测学习和实际系统的反馈学习，在另一方面，也可以进行控制单元的模拟学习和强化学习。
其次，GAN还可以用以解决标注数据不足时的学习问题，常见的就是无监督学习。
再者，GAN在NLP领域也具有大显身手的能力，比如生成对话、由文本生成图像等。这种从潜在分布生成“无限”新样本的能力，在AI对图像和视觉计算、语音和语言处理、互联网与大型系统信息安全等领域具有重大的应用价值，这也是目前发展GAN对研究人工智能的主要意义。

